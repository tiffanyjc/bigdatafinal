<!DOCTYPE HTML>
<!--
	Telephasic by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
        <title>Using Business Data to Assess Characteristics of Urban Environments</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
	</head>
	<body class="homepage">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header-wrapper">
					<div id="header" class="container">

						<!-- Logo -->
							<h1 id="logo"><a href="index.html">Big Data Final</a></h1>

						<!-- Nav -->
							<nav id="nav">
								<ul>
									<li>
										<a href="#">Dropdown</a>
										<ul>
											<li><a href="#">Lorem ipsum dolor</a></li>
											<li><a href="#">Magna phasellus</a></li>
											<li><a href="#">Etiam dolore nisl</a></li>
											<li>
												<a href="#">Phasellus consequat</a>
												<ul>
													<li><a href="#">Lorem ipsum dolor</a></li>
													<li><a href="#">Phasellus consequat</a></li>
													<li><a href="#">Magna phasellus</a></li>
													<li><a href="#">Etiam dolore nisl</a></li>
												</ul>
											</li>
											<li><a href="#">Veroeros feugiat</a></li>
										</ul>
									</li>
									<li><a href="left-sidebar.html">Left Sidebar</a></li>
									<li class="break"><a href="right-sidebar.html">Right Sidebar</a></li>
									<li><a href="no-sidebar.html">No Sidebar</a></li>
								</ul>
							</nav>

					</div>

					<!-- Hero -->
						<section id="hero" class="container">
							<header>
                                <h2>Using Business Data to <br />Assess Characteristics of Urban Environments</h2>
							</header>
							<p>Research conducted by Jaclyn Zhong, Reena Zhan, and Tiffany Chen</p>
							
						</section>

				</div>

			<!-- Features 1 -->
<!--
				<div class="wrapper">
					<div class="container">
						<div class="row">
							<section class="6u 12u(narrower) feature">
								<div class="image-wrapper first">
									<a href="#" class="image featured first"><img src="images/pic01.jpg" alt="" /></a>
								</div>
								<header>
									<h2>Semper magna neque vel<br />
									adipiscing curabitur</h2>
								</header>
								<p>Lorem ipsum dolor sit amet consectetur et sed adipiscing elit. Curabitur vel
								sem sit dolor neque semper magna. Lorem ipsum dolor sit amet consectetur et sed
								adipiscing elit. Curabitur vel sem sit.</p>
								<ul class="actions">
									<li><a href="#" class="button">Elevate my awareness</a></li>
								</ul>
							</section>
							<section class="6u 12u(narrower) feature">
								<div class="image-wrapper">
									<a href="#" class="image featured"><img src="images/pic02.jpg" alt="" /></a>
								</div>
								<header>
									<h2>Amet lorem ipsum dolor<br />
									sit consequat magna</h2>
								</header>
								<p>Lorem ipsum dolor sit amet consectetur et sed adipiscing elit. Curabitur vel
								sem sit dolor neque semper magna. Lorem ipsum dolor sit amet consectetur et sed
								adipiscing elit. Curabitur vel sem sit.</p>
								<ul class="actions">
									<li><a href="#" class="button">Elevate my awareness</a></li>
								</ul>
							</section>
						</div>
					</div>
				</div>
-->

		

			<!-- Features 2 -->
				<div class="wrapper">
					<section class="container">
						<header class="major">
                            <h2>1:&nbsp; What do city residents value in businesses? </h2>
						</header>
                        
                        
                        
                        <p>
                            How friendly are New Yorkers compared to individuals living in San Francisco? Do people in Pittsburgh value time and efficiency as much as residents in Las Vegas? While there certainly exist commonalities and unifying characteristics across cities, there also exist distinguishing traits that are unique to any given city. Additionally, the cultural atmosphere of a city relies in large part on its residents, meaning that the success of a business may vary across cities and geographical locations, depending on the degree of importance residents place on a given business trait.  </p>

                        <p>
                            The first portion of our research seeks to understand how we can use aggregated review data to identify traits that make a business successful or unsuccessful within its specific geographical region. We will limit our scope to a state-by-state basis with the USA, using curated review data from Yelp. 
                        
                        </p>
                        
                        <header class="major">
                        <p>Procedure</p>
                        </header>
                        
                        <p>
                            After data wrangling, we will split our procedure into two different parts: the first section will set out to make more observatory analyses of the given data, while the second section uses the data to begin training a predictive model to generate insight if we were given more review data in the future. 
                        </p>
                        
                        <h3>Phase 0: Data Wrangling </h3>
                        <p></p>
                        <p>
                            We begin by converting the review data from JSON into a CSV file, using the list of businesses provided to also relate a review to the location it was written for, and separating all the review data into CSV’s of review data based on state in the US. 
                            
                        </p>
                        <p>
                            In preparation for data analysis, we also removed reviews with associated ratings of 3 (out of 5) stars, as they were considered neutral (and thus unnecessary) for our analyses. The following table shows the final number of reviews tied to each US state that was provided to us within the whole dataset. 
                        </p>
                        
                        <b>Table 1.1: Number of 1, 2, 4, 5 star reviews for US states</b>
                        
                        <table>
                            <tr><td><b>STATE</b>
                                </td>
                                <td><b># REVIEWS</b>
                                </td>
                            </tr>
                            <tr><td>VT
                                </td>
                                <td>4
                                </td>
                            </tr>
                            <tr><td>AZ
                                </td>
                                <td>1265915
                                </td>
                            </tr>
                            <tr><td>WI
                                </td>
                                <td>88778
                                </td>
                            </tr>
                            <tr><td>NV
                                </td>
                                <td>1460806
                                </td>
                            </tr>
                            <tr><td>OH
                                </td>
                                <td>190786
                                </td>
                            </tr>
                            <tr><td>NC
                                </td>
                                <td>233703
                                </td>
                            </tr>
                            <tr><td>SC
                                </td>
                                <td>7379
                                </td>
                            </tr>
                            <tr><td>PA
                                </td>
                                <td>179774
                                </td>
                            </tr>
                            <tr><td>IL
                                </td>
                                <td>29874
                                </td>
                            </tr>
                            <tr><td>NY
                                </td>
                                <td>99
                                </td>
                            </tr>
                        </table>
                        
                        <h3>Phase 1: Observatory analyses </h3>

                        <p>
                            We begin by assessing the polarity and subjectivity of reviews based on their textual content. We define polarity as the expressed opinion in a document (i.e. positive, negative, or neutral) and subjectivity as the overall individual feeling / experience that is embodied within the text. 
                        </p>

                        <p>
                            Using the Python TextBlob, we ran sentiment analyses to obtain polarity and subjectivity scores for 1) all positive / negative reviews together, 2) positive reviews only, and 3) negative reviews only for each state listed in Table 1.1. 
                        </p>
                        
                        <img src="img/Fig12.JPG">
                        
                        <p>
                            From there, we also extract subsets of a maximum of 10,000 words from all the reviews within a given state to obtain word-count tables containing the top 100 words with highest frequencies (excluding filler / meaningless words). 

                        </p>
                        
                        <p>
                        
                            We attach the table with highest frequency words for each state as Appendix A. 
                        </p>
                        
                        <h3>Phase 2: Phase 2: Model training / prediction </h3>
                        
                        <p>
                            We then proceed to train a model using big data to predict the average number of stars based on the textual content of a review. In this model, we use an iterative stochastic gradient ascent on randomized subsets of our data to obtain an optimized model. We use a gradient ascent rather than a descent because by we use a logistic regression to maximize our likelihood function rather than minimize our loss function. 
                        </p>
                        
                        <p>
                            More specifically, in Python we create an iterator which loops through subsets of review data of size 1000 and clean the review text through tokenizing and stemming the words in reviews, which are then passed to a hashing vectorizer so as to match words with different suffixes but similar meanings / intentions. 

                        </p>
                        
                        <p>
                            We then, using the hashing vectorizer along with a bag of words model containing negative and positive sentiment-associated words, loop through the review iterator to train our model on the subset data. 

                        </p>
                        
                        <p>
                            We then plot our accuracy in predicting review ratings as a function of the iteration they are on (we omit several states’ individual accuracies because the number of reviews they had wasn’t enough to train a full model): 
                        </p>
                        
                        <img src="img/Fig13.JPG"> 
                        
                        <p></p>
                        <img src="img/Fig14.JPG"> 
                        <img src="img/Fig15.JPG"> 
                        <img src="img/Fig16.JPG"> 
                        
                        <header class="major">
                            <p>Key Findings</p>
                        </header>
                        
                        <p>
                            Based on our data analyses, we observe three key findings: 
                        </p>
                        
                        <ol>
                            <li><b>1: &nbsp; Positive and negative rating reviews can easily be distinguished by their polarity</b></li>
                            <p></p>
                            While intuitively this is exactly what we had anticipated, the differences in average polarity of negative versus positive reviews were unexpectedly significant (see Table 1.3). As a result, we observe that a first-pass NLP approach for sentiment analysis is extremely effective at distinguishing between reviews that are positive and reviews that are negative, and that these NLP characteristics are in line with the ultimate rating that the reviewer gave to the business.  
                            <p></p>
                            
                            <b>Table 1.3: Averaged Sentiments Across Reviews</b>
                            <table>
                                <tr>
                                    <td></td>
                                    <td><b>Total</b></td>
                                    <td><b>Negative</b></td>
                                    <td><b>Positive</b></td>
                                </tr>
                                <tr>
                                    <td><b>Polarity</b></td>
                                    <td>0.237641</td>
                                    <td>0.00839374444</td>
                                    <td>
                                        0.3240234444
                                    </td>
                                </tr>
                                <tr>
                                    <td><b>Subjectivity</b></td>
                                    <td>0.56574</td>
                                    <td>0.519134</td>
                                    <td>0.57551822</td>
                                </tr>
                            
                            </table>
                            
                            
                            <li><b>2: The content and structure / composition of a review varies significantly depending on ratings 
                                </b></li>
                            <p></p>
                            Based on the word frequency tables obtained by state (see Appendix A), a heuristic analysis showed a consistent pattern across reviews that were negative (1, 2 stars) or positive (4, 5 stars). It was found that positive reviews included more frequent usages of adjectives, which were either used to describe people (i.e. “friendly”, “awesome”, “amazing”) or to describe food (“delicious”, “cheap”, etc.). 
                            <p></p>
                            On the other hand, negative reviews had an unexpectedly high frequency of nouns, specifically referencing people (i.e. “staff”, “waiter”, “manager”, “waitress”, “customer”, etc.). In addition to mentions of people and human interactions, other aspects of businesses that surfaced in the frequency tables included money (“expensive”, “price”) and location (“area”, “location”, “parking”). 

                            <p></p>
                            <li><b>3: Some states culturally seem to have more demonstrative / indicative reviews of their feelings about food; we can predict the rating given by a review according to its text description with a relatively high accuracy </b></li>
                            <p></p>
                            
                            While the accuracy for our SGD model was approximately 78% (Figure 1.3) when trained with review data from all our given states, selectively training our model state by state (i.e. Figures 1.4 - 1.6) showed that in some cases, there was approximately a 10% increase in model accuracy, which implies that reviews in certain states offer more insight via positive / negative sentiment into the ultimate review rating. 
                        </ol>
                        
                        <header class="major">
                            <p>Implications</p>
                        </header>
                        
                        <p>Overall, our findings suggest potential ways to increase both new and veteran businesses’ success in Yelp ratings. 
                           
                        </p>
                        
                        <p>
                            For businesses owners who are considering opening up shop in a particular state, they will now have a better idea of which areas of their business to strengthen in preparation for opening day (i.e. better customer service, cutting costs in order to reduce menu prices, etc.); for business owners who are considering expanding to a new geographical area, the research findings provide a good way of gauging whether there exists a synergy between the existing business’ strengths and the needs of their new customer base. 
                            
                        </p>
                        
                        <p>
                            For businesses who want a better idea of their performance relative to their competitors, being able to analyze more data than simply the average star rating will provide a more nuanced insight into why their business is performing worse relative to others, and which exact features of their business they can focus on so as to intentionally target an increase in their average review rating.
                        </p>
                        
                        <header class="major">
                            <p>Extensions</p>
                        </header>
                        
                        <p>
                            Finally, we end this portion of our research by noting several improvements that can be made to our current procedure, given longer periods of time and more detailed data. Firstly, it seems likely that there may be varying tendencies / habits in giving ratings across different user demographics and geographical locations. For example, it is possible that older people are more likely to write a positive review than an individual in their early 20s. Perhaps New Yorkers have higher standards and are more frugal with handing out 5 stars. As a result, if we had been given more extensive user data and been able to observe users’ habits across different businesses, we could expect that normalizing our data would improve the accuracy of our model. 
                            
                        </p>
                        
                        <p>
                            Additionally, had we been given more data across more states, it would have made sense to also run a sentiment analysis across different regions of the US (i.e. Northeast, Midwest, etc.) to observe review behaviors on a more macro, regional level than simply by state. 
                        </p>
<!--
						<div class="row features">
							<section class="4u 12u(narrower) feature">
								<div class="image-wrapper first">
									<a href="#" class="image featured"><img src="images/pic03.jpg" alt="" /></a>
								</div>
								<p>Lorem ipsum dolor sit amet consectetur et sed adipiscing elit. Curabitur
								vel sem sit dolor neque semper magna lorem ipsum.</p>
							</section>
							<section class="4u 12u(narrower) feature">
								<div class="image-wrapper">
									<a href="#" class="image featured"><img src="images/pic04.jpg" alt="" /></a>
								</div>
								<p>Lorem ipsum dolor sit amet consectetur et sed adipiscing elit. Curabitur
								vel sem sit dolor neque semper magna lorem ipsum.</p>
							</section>
							<section class="4u 12u(narrower) feature">
								<div class="image-wrapper">
									<a href="#" class="image featured"><img src="images/pic05.jpg" alt="" /></a>
								</div>
								<p>Lorem ipsum dolor sit amet consectetur et sed adipiscing elit. Curabitur
								vel sem sit dolor neque semper magna lorem ipsum.</p>
							</section>
						</div>
-->
						
					</section>
				</div>

				<div class="wrapper">
					<section class="container">
						<header class="major">
                            <h2>2:&nbsp; Are attributes of area businesses predictive of average socioeconomic status in an area? </h2>
						</header>
                        
                        <p>
							We now move to an exploration of how data from the Yelp Dataset Challenge can predict the wealth level of people living particular areas. For this part of the project, we were interested in identifying features of businesses that were in some sense suggestive of the socioeconomic landscape of a particular area or neighborhood. We hypothesized, for example, that areas with a higher number of restaurants that are ‘upscale’ or expensive would tend to be areas where the residents have higher income. Similarly, we hypothesized that areas with more inexpensive restaurants would tend to be areas where the residents have lower income levels. Our objective in this part of the project was to assess how exactly how predictive the business data could be of socioeconomic status of particular locations.
                        </p>
                        
                        <header class="major">
                        	<p>Procedure</p>

                        	<h3>Obtaining socioeconomic status information<h3>
							
							<p>Our first step was to find a secondary data source that would indicate socioeconomic status of a particular area. We ended up using <a href="https://www.irs.gov/uac/soi-tax-stats-individual-income-tax-statistics-zip-code-data-soi">tax data from the IRS</a>, which supplied adjusted gross income (AGI) data segmented by zip code and income bracket. We used the most recent data set (from 2014) and did some cleaning and data aggregation in order to produce a CSV with the following information: zip code | state | average adjusted gross income. For our purposes, we excluded information for all zip codes except those of cities which were in the Yelp dataset.</p>

							<p>While doing this, we noted the following particularities of this data set:</p>
							<ul>
							<li>The data probably overestimates income levels since many people are not required by federal law to file tax returns because they do not make enough money. We do not believe this had a significant effect on the results we describe below.</li>
							<li>The data was segmented by both zip code and income bracket, so we extrapolated from the number of returns information and took a weighted average to get an estimate of average AGI by zip code.</li>
							</ul>
							<ul>

							<h3>Wrangling business data<h3>

							<p>We also parsed and processed the business data as follows:</p>
							<ul>
							<li>Trimmed the data set to American businesses (since we only had income information for the U.S.).</li>
							<li>Matched businesses to their average AGI using the information generated in the previous step.</li>
							<li>Created binary features on the category information. The categories are along the lines of the following:</li>
							<ul>
							<li>Beauty &amp; Spas</li>
							<li>Health &amp; Medical</li>
							<li>Nightlife</li>
							<li>Arts &amp; Entertainment</li>
							<li>Etc.</li>
							</ul>
							</ul>

							<h3>Predicting wealth of business&rsquo; neighborhood using regression trees<h3>

							<p>As a first attempt to tackle our research question, we used regression trees to predict the wealth of a particular business&rsquo; location (determined by zip code), using category information as features. We tuned the regression tree by varying the maximum number of features examined to determine each split and by varying the depth of the tree, and we noticed that this did seem to improve our results.</p>

							<p>We split the data into a training set (80%) and a testing set (20%). (This step was also done for the other regression tree/gradient boosted regression tree models we generated.) The results of this first round of prediction are below:</p>

							<p><strong>Table 2.1</strong> Predicting business area wealth by business characteristics &mdash; regression tree MSE values by max features examined per split and max tree depth</p>

							<table>
							<tbody>
							<tr>
							<td>
							<p>feat=.1</p>
							</td>
							<td>
							<p>feat=.2</p>
							</td>
							<td>
							<p>feat=.3</p>
							</td>
							<td>
							<p>feat=.4</p>
							</td>
							</tr>
							<tr>
							<td>
							<p>depth=2</p>
							</td>
							<td>
							<p>2127.38756699</p>
							</td>
							<td>
							<p>2121.66437611</p>
							</td>
							<td>
							<p>2122.67506738</p>
							</td>
							<td>
							<p>2112.8490354</p>
							</td>
							</tr>
							<tr>
							<td>
							<p>depth=4</p>
							</td>
							<td>
							<p>2109.25540175</p>
							</td>
							<td>
							<p>2106.00052076</p>
							</td>
							<td>
							<p>2103.62800319</p>
							</td>
							<td>
							<p>2102.98962337</p>
							</td>
							</tr>
							<tr>
							<td>
							<p>depth=6</p>
							</td>
							<td>
							<p>2106.7270169</p>
							</td>
							<td>
							<p>2093.65241749</p>
							</td>
							<td>
							<p><strong><em>2088.41843785</em></strong></p>
							</td>
							<td>
							<p>2092.31124289</p>
							</td>
							</tr>
							</tbody>
							</table>

							<p>Even with the most optimal set of parameters, however, we noticed that the MSE values were still very high. (They are reported above in thousands of dollars.)</p>

							<h3>Predicting wealth of business&rsquo; neighborhood using gradient boosted regression trees<h3>

							<p>Our next approach was to use gradient boosted regression trees; we hoped that this would improve the predictive power of the model. Analogous results to those presented for the regression trees are presented below:</p>
							
							<p><strong>Table 2.2</strong> Predicting business area wealth by business characteristics &mdash; gradient boosted regression tree MSE values by max features examined per split and max tree depth</p>

							<table>
							<tbody>
							<tr>
							<td>
							<p>feat=.1</p>
							</td>
							<td>
							<p>feat=.2</p>
							</td>
							<td>
							<p>feat=.3</p>
							</td>
							<td>
							<p>feat=.4</p>
							</td>
							</tr>
							<tr>
							<td>
							<p>depth=2</p>
							</td>
							<td>
							<p>2071.69089944</p>
							</td>
							<td>
							<p>2068.95690973</p>
							</td>
							<td>
							<p>2069.50609851</p>
							</td>
							<td>
							<p>2068.48800992</p>
							</td>
							</tr>
							<tr>
							<td>
							<p>depth=4</p>
							</td>
							<td>
							<p>2055.30749086</p>
							</td>
							<td>
							<p>2052.90528437</p>
							</td>
							<td>
							<p>2051.90428652</p>
							</td>
							<td>
							<p>2051.74584601</p>
							</td>
							</tr>
							<tr>
							<td>
							<p>depth=6</p>
							</td>
							<td>
							<p>2046.58963345</p>
							</td>
							<td>
							<p>2045.63039901</p>
							</td>
							<td>
							<p><strong><em>2043.01621297</em></strong></p>
							</td>
							<td>
							<p>2044.72819485</p>
							</td>
							</tr>
							</tbody>
							</table>

							<p>Still, we observed that MSE values were high, even with the most optimal set of parameters, as we can see from the above table.</p>
							
							<h3>Reducing business data set to restaurants in order to add more features<h3>

							<p>We suspected that the data set we were working with was lacking in features, so our next step was to enrich the set with more features. The natural next place to look for features in our data set was in the attributes field, since we had already exhausted all of the category information. However, we noticed that attributes were only indicated for businesses that are restaurants, so we decided to narrow our focus exclusively to restaurants in the dataset. </p>

							<p>We then parsed and binarized the attribute information. (This was non-trivial since the attribute information is much richer than the category information. While category information is just a list of categories, attribute information is nested on multiple levels and each attribute key can take on several different types of values rather than just binary values.</p>

							<p>We ran the restaurant data through the gradient boosted regression tree model and obtained the following results:</p>

							<p><strong>Table 2.3</strong> Predicting restaurant area wealth by restaurant characteristics &mdash; gradient boosted regression tree MSE values by max features examined per split and max tree depth</p>

							<table>
							<tbody>
							<tr>
							<td>
							<p>feat=.1</p>
							</td>
							<td>
							<p>feat=.2</p>
							</td>
							<td>
							<p>feat=.3</p>
							</td>
							<td>
							<p>feat=.4</p>
							</td>
							</tr>
							<tr>
							<td>
							<p>depth=2</p>
							</td>
							<td>
							<p>2112.34324877</p>
							</td>
							<td>
							<p>2105.05695268</p>
							</td>
							<td>
							<p>2118.50388279</p>
							</td>
							<td>
							<p>2098.7166738</p>
							</td>
							</tr>
							<tr>
							<td>
							<p>depth=4</p>
							</td>
							<td>
							<p>2072.40706255</p>
							</td>
							<td>
							<p>2067.64289723</p>
							</td>
							<td>
							<p>2067.23118337</p>
							</td>
							<td>
							<p>2060.12189132</p>
							</td>
							</tr>
							<tr>
							<td>
							<p>depth=6</p>
							</td>
							<td>
							<p>2065.75468912</p>
							</td>
							<td>
							<p>2050.02884825</p>
							</td>
							<td>
							<p>2046.44203703</p>
							</td>
							<td>
							<p>2051.93046732</p>
							</td>
							</tr>
							</tbody>
							</table>

							<p>Since the MSE measures remained high across the board, we decided to move to a different model to examine the problem of predicting socioeconomic wealth using business data.</p>
<h3>Gathering insights from regression tree/gradient boosted regression tree<h3>
</ul>
<p>We decided that an appropriate next step would be to &ldquo;flip&rdquo; the model and predict the wealth of an area based on the businesses in the area. We wanted to run an OLS regression to do this, but it was not immediately clear how to aggregate the business data into an appropriate format for OLS regression. We looked to the previous regression tree models for indications of what regressors might be appropriate. We looked at the best-performing regression tree, which we include as an attachment. (TODO!!!)</p>
<p>From the tree, we looked at features which split the data at a particular node into two sizeable groups rather than splitting so that one group has only a few data points: we thought that these features were indicative of larger trends in the whole data set rather than smaller particularities of the sample that we have. This set of features is below:</p>
<p><strong>Table 2.4</strong> Important features from best performing regression tree on restaurant data</p>
<ul>
<li><strong><strong>Predicting wealth of zip code based on restaurant data using OLS regression</strong></strong></li>
</ul>
<p>We parsed the restaurant data used for the regression trees, aggregating by zip code on the key features identified in the previous step. That is, for each zip code, we calculated how many restaurants satisfied each of the above characteristics. Each of these counts was then a regressor in our first OLS model. We include the results for this regression below:</p>
<p><strong>Table 2.5</strong> Regression using important features from best performing regression tree on restaurant data</p>
<p>We then added a &lsquo;total_businesses&rsquo; regressor to control for the effects of having a high number of businesses in general in a particular zip code, which yielded the following regressors and results.</p>
<p><strong>Table 2.6</strong> Important features from best performing regression tree on restaurant data, with control</p>
<p><br /><br /></p>
<p><strong>Table 2.7</strong> Regression using important features from best performing regression tree on restaurant data, with control</p>
<p><br /><br /></p>
<p>We observed that, while a number of the coefficients in the regression above were statistically significant, many were not. In an effort to simplify the regression, we removed all the regressors whose associated p-value were greater than .50. This left us with the following regressors and corresponding OLS regression results:</p>
<p><strong>Table 2.8</strong> Reduced features from best performing regression tree on restaurant data, with control</p>
<p><br /><br /></p>
<p><strong>Table 2.9</strong> Regression using reduced features from best performing regression tree on restaurant data, with control</p>
<p><br /><br /></p>
                        </header>

                        <header class="major">
                            <p>Key Findings</p>
                        </header>
                        
                        <header class="major">
                            <p>Implications</p>
                        </header>
                        
                        <header class="major">
                            <p>Extensions</p>
                        </header>
<!--
						<div class="row features">
							<section class="4u 12u(narrower) feature">
								<div class="image-wrapper first">
									<a href="#" class="image featured"><img src="images/pic03.jpg" alt="" /></a>
								</div>
								<p>Lorem ipsum dolor sit amet consectetur et sed adipiscing elit. Curabitur
								vel sem sit dolor neque semper magna lorem ipsum.</p>
							</section>
							<section class="4u 12u(narrower) feature">
								<div class="image-wrapper">
									<a href="#" class="image featured"><img src="images/pic04.jpg" alt="" /></a>
								</div>
								<p>Lorem ipsum dolor sit amet consectetur et sed adipiscing elit. Curabitur
								vel sem sit dolor neque semper magna lorem ipsum.</p>
							</section>
							<section class="4u 12u(narrower) feature">
								<div class="image-wrapper">
									<a href="#" class="image featured"><img src="images/pic05.jpg" alt="" /></a>
								</div>
								<p>Lorem ipsum dolor sit amet consectetur et sed adipiscing elit. Curabitur
								vel sem sit dolor neque semper magna lorem ipsum.</p>
							</section>
						</div>
-->
						
					</section>
				</div>

			<!-- Footer -->
				<div id="footer-wrapper">
					<div id="footer" class="container">
						<header class="major">
							<h2>Euismod aliquam vehicula lorem</h2>
							<p>Lorem ipsum dolor sit amet consectetur et sed adipiscing elit. Curabitur vel sem sit<br />
							dolor neque semper magna lorem ipsum feugiat veroeros lorem ipsum dolore.</p>
						</header>
						
					</div>
					<div id="copyright" class="container">
						<ul class="menu">
							<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</div>
				</div>

		</div>

		<!-- Scripts -->

			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>